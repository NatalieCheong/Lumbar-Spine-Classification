{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1qTv-GUnoc8"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim.lr_scheduler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import pydicom\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import confusion_matrix, log_loss\n",
        "import timm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import from our modules\n",
        "from data_visualization import LumbarSpineVisualizer\n",
        "from pattern_analysis import PatternAnalyzer\n",
        "from preprocessing_pipeline import (\n",
        "    preprocess_image,\n",
        "    save_processed_data,\n",
        "    process_fold_data,\n",
        "    create_stratified_folds\n",
        ")\n",
        "from classification_model import (\n",
        "    LumbarSpineDataset,\n",
        "    AttentionBlock,\n",
        "    LumbarClassifier,\n",
        "    train_epoch as train_classification,\n",
        "    validate as validate_classification\n",
        ")\n",
        "from regression_model import (\n",
        "    LumbarSpineRegDataset,\n",
        "    LumbarRegressor,\n",
        "    WeightedL1Loss,\n",
        "    train_epoch as train_regression,\n",
        "    validate as validate_regression\n",
        ")\n",
        "from evaluation_metrics import (\n",
        "    compute_competition_metric,\n",
        "    evaluate_model,\n",
        "    evaluate_regression_model\n",
        ")\n",
        "from prediction_pipeline import (\n",
        "    OptimizedPredictionPipeline,\n",
        "    predict_preprocessed_samples\n",
        ")\n",
        "from advanced_analysis import AdvancedAnalysis\n",
        "\n",
        "class LumbarSpineAnalysis:\n",
        "    \"\"\"Main class for lumbar spine analysis\"\"\"\n",
        "    def __init__(self, base_path: str):\n",
        "        self.base_path = Path(base_path)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {device}\")\n",
        "\n",
        "        # Initialize components\n",
        "        self.initialize_components()\n",
        "\n",
        "    def initialize_components(self):\n",
        "        \"\"\"Initialize all necessary components\"\"\"\n",
        "        # Load data\n",
        "        self.train_df = pd.read_csv(self.base_path / 'train.csv')\n",
        "        self.coords_df = pd.read_csv(self.base_path / 'train_label_coordinates.csv')\n",
        "        self.series_df = pd.read_csv(self.base_path / 'train_series_descriptions.csv')\n",
        "\n",
        "        # Create visualizer\n",
        "        self.visualizer = LumbarSpineVisualizer()\n",
        "\n",
        "        # Initialize models\n",
        "        self.classification_model = None\n",
        "        self.regression_model = None\n",
        "        self.prediction_pipeline = None\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"Preprocess and save data\"\"\"\n",
        "        print(\"Creating stratified folds...\")\n",
        "        folds = create_stratified_folds(self.train_df)\n",
        "\n",
        "        print(\"Processing training data...\")\n",
        "        train_samples = process_fold_data(\n",
        "            study_ids=folds[0]['train'],\n",
        "            base_path=self.base_path,\n",
        "            coords_df=self.coords_df,\n",
        "            series_df=self.series_df,\n",
        "            train_df=self.train_df,\n",
        "            augment=True\n",
        "        )\n",
        "\n",
        "        print(\"Processing validation data...\")\n",
        "        val_samples = process_fold_data(\n",
        "            study_ids=folds[0]['val'],\n",
        "            base_path=self.base_path,\n",
        "            coords_df=self.coords_df,\n",
        "            series_df=self.series_df,\n",
        "            train_df=self.train_df,\n",
        "            augment=False\n",
        "        )\n",
        "\n",
        "        # Save processed data\n",
        "        save_processed_data(train_samples, 'train_processed.npy')\n",
        "        save_processed_data(val_samples, 'val_processed.npy')\n",
        "\n",
        "        return train_samples, val_samples\n",
        "\n",
        "    def train_classification_model(self, train_samples, val_samples):\n",
        "        \"\"\"Train classification model\"\"\"\n",
        "        print(\"\\nTraining Classification Model...\")\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = LumbarSpineDataset(train_samples, augment=True)\n",
        "        val_dataset = LumbarSpineDataset(val_samples, augment=False)\n",
        "\n",
        "        # Create dataloaders\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "        # Initialize model\n",
        "        self.classification_model = LumbarClassifier().to(self.device)\n",
        "\n",
        "        # Training parameters\n",
        "        criterion = nn.CrossEntropyLoss(\n",
        "            weight=torch.tensor([1.0, 4.75, 12.29]).to(self.device)\n",
        "        )\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            self.classification_model.parameters(),\n",
        "            lr=1e-4,\n",
        "            weight_decay=0.01\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer,\n",
        "            T_max=30,\n",
        "            eta_min=1e-6\n",
        "        )\n",
        "\n",
        "        # Training loop\n",
        "        best_val_acc = 0\n",
        "        for epoch in range(30):\n",
        "            train_loss, train_acc = train_classification(\n",
        "                self.classification_model, train_loader, criterion, optimizer, self.device\n",
        "            )\n",
        "            val_loss, val_acc = validate_classification(\n",
        "                self.classification_model, val_loader, criterion, self.device\n",
        "            )\n",
        "            scheduler.step()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/30:\")\n",
        "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(self.classification_model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    def train_regression_model(self, train_samples, val_samples):\n",
        "        \"\"\"Train regression model\"\"\"\n",
        "        print(\"\\nTraining Regression Model...\")\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = LumbarSpineRegDataset(train_samples, augment=True)\n",
        "        val_dataset = LumbarSpineRegDataset(val_samples, augment=False)\n",
        "\n",
        "        # Create dataloaders\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "        # Initialize model\n",
        "        self.regression_model = LumbarRegressor().to(self.device)\n",
        "\n",
        "        # Training parameters\n",
        "        criterion = WeightedL1Loss()\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            self.regression_model.parameters(),\n",
        "            lr=1e-4,\n",
        "            weight_decay=0.01\n",
        "        )\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer,\n",
        "            T_max=30,\n",
        "            eta_min=1e-6\n",
        "        )\n",
        "\n",
        "        # Training loop\n",
        "        best_val_loss = float('inf')\n",
        "        for epoch in range(30):\n",
        "            train_loss = train_regression(\n",
        "                self.regression_model, train_loader, criterion, optimizer, self.device\n",
        "            )\n",
        "            val_loss, val_mae = validate_regression(\n",
        "                self.regression_model, val_loader, criterion, self.device\n",
        "            )\n",
        "            scheduler.step()\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/30:\")\n",
        "            print(f\"Train Loss: {train_loss:.4f}\")\n",
        "            print(f\"Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}\")\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                torch.save(self.regression_model.state_dict(), 'best_regression_model.pth')\n",
        "\n",
        "    def analyze_results(self, val_samples):\n",
        "        \"\"\"Analyze model results\"\"\"\n",
        "        # Load best models\n",
        "        self.classification_model.load_state_dict(torch.load('best_model.pth'))\n",
        "        self.regression_model.load_state_dict(torch.load('best_regression_model.pth'))\n",
        "\n",
        "        # Create prediction pipeline\n",
        "        self.prediction_pipeline = OptimizedPredictionPipeline(\n",
        "            self.classification_model,\n",
        "            self.device\n",
        "        )\n",
        "\n",
        "        # Create analyzer\n",
        "        analyzer = AdvancedAnalysis(\n",
        "            self.prediction_pipeline,\n",
        "            'val_processed.npy'\n",
        "        )\n",
        "\n",
        "        # Run analyses\n",
        "        print(\"\\nRunning Statistical Analysis...\")\n",
        "        stats_results = analyzer.analyze_prediction_patterns(num_samples=500)\n",
        "\n",
        "        print(\"\\nAnalyzing Challenging Cases...\")\n",
        "        analyzer.analyze_challenging_cases(num_cases=5)\n",
        "\n",
        "    def predict_new_cases(self, image_paths: List[str]):\n",
        "        \"\"\"Predict on new cases\"\"\"\n",
        "        for image_path in image_paths:\n",
        "            # Load and preprocess image\n",
        "            dcm = pydicom.dcmread(image_path)\n",
        "            image = dcm.pixel_array\n",
        "            processed_image = preprocess_image(image)\n",
        "\n",
        "            # Make prediction\n",
        "            prediction = self.prediction_pipeline.predict(\n",
        "                torch.from_numpy(processed_image).unsqueeze(0),\n",
        "                condition='Spinal Canal Stenosis',  # Example condition\n",
        "                level='L4_L5'  # Example level\n",
        "            )\n",
        "\n",
        "            # Visualize results\n",
        "            self.visualizer.plot_prediction(\n",
        "                image,\n",
        "                prediction,\n",
        "                title=f\"Prediction for {Path(image_path).name}\"\n",
        "            )\n",
        "\n",
        "def main():\n",
        "    # Initialize\n",
        "    base_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
        "    analyzer = LumbarSpineAnalysis(base_path)\n",
        "\n",
        "    # Preprocess data\n",
        "    train_samples, val_samples = analyzer.preprocess_data()\n",
        "\n",
        "    # Train models\n",
        "    analyzer.train_classification_model(train_samples, val_samples)\n",
        "    analyzer.train_regression_model(train_samples, val_samples)\n",
        "\n",
        "    # Analyze results\n",
        "    analyzer.analyze_results(val_samples)\n",
        "\n",
        "    # Optional: Predict on new images\n",
        "    # new_images = ['path/to/image1.dcm', 'path/to/image2.dcm']\n",
        "    # analyzer.predict_new_cases(new_images)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}